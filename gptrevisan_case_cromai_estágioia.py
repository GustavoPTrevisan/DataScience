# -*- coding: utf-8 -*-
"""GPTrevisan_Case_Cromai_EstágioIA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qGHZqBdarOIOHP8k4fdrmU8b3niXVacF

#**Case de Avaliação de modelos de machine lerning.**

##**Gustavo Pavanello Trevisan**

O data set utilizado nessa avaliação está disponível em [Star dataset to predict star types](https://www.kaggle.com/deepu1109/star-dataset)
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd
import matplotlib.pyplot as plt
from google.colab import files
uploaded = files.upload()

import io

stars = pd.read_csv('Stars.csv', encoding = 'unicode_escape')

stars.shape

type(stars)

stars.info

stars.columns

stars

print(stars.groupby("Star type").size())

import seaborn as sns
human_readable_star_types = stars['Star type'].replace(
    {
      0: "Brown Dwarf",
      1: "Red Dwarf",
      2: "White Dwarf",
      3: "Main Sequence",
      4: "Supergiant",
      5: "Hypergiant"
    },
    inplace=True
  )
sns.countplot(human_readable_star_types, label="Count")
print(human_readable_star_types)

plt.show()

"""**O gráfico acimos nos mostra que nossos dados alvo tem uma distribuição simétrica, o que faz com que o método de avaliação através da acurácia dos modelos (que criaremos mais a frente) nos deem uma boa noção de sua eficácia.**"""

stars.drop('Star type', axis=1).plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(12,12), 
                                        title='Box Plot for each input variable')
plt.savefig('Stars_box')
plt.show()

import pylab as pl
stars.drop('Star type' ,axis=1).hist(bins=30, figsize=(12,12))
pl.suptitle("Histogram for each numeric input variable")
plt.savefig('Stars_hist')
plt.show()

from pandas.plotting import scatter_matrix
from matplotlib import cm
feature_names = ['Temperature (K)', 'Luminosity(L/Lo)', 'Radius(R/Ro)', 'Absolute magnitude(Mv)']
X = stars[feature_names]
y = stars['Star type']
cmap = cm.get_cmap('gnuplot')
scatter = scatter_matrix(X, c = y, marker = 'o', s=40, hist_kwds={'bins':15}, figsize=(10,10), cmap = cmap)
plt.suptitle('Scatter-matrix for each input variable')
plt.savefig('Stars_scatter_matrix')

correlacao = stars.corr(method='pearson',min_periods=1)
correlacao.loc['Star type',:]

sns.heatmap(correlacao)

"""### **A partir do gráfico de calor e dos números de correlação, podemos verificar que a variável de tipo de estrela tem uma alta correlação com a luminosidade e o raio da estrela**"""

stars.describe()

"""#**Criando os sets de treinamento e teste e aplicando a escala**

"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""#**Construindo Modelos e verificando através da acurácia.**"""

# Logistic Regression
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
print('Accuracy of Logistic regression classifier on training set: {:.2f}'
     .format(logreg.score(X_train, y_train)))
print('Accuracy of Logistic regression classifier on test set: {:.2f}'
     .format(logreg.score(X_test, y_test)))

# Decision Tree

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier().fit(X_train, y_train)
print('Accuracy of Decision Tree classifier on training set: {:.2f}'
     .format(clf.score(X_train, y_train)))
print('Accuracy of Decision Tree classifier on test set: {:.2f}'
     .format(clf.score(X_test, y_test)))

# K-Nearest Neighbors

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
print('Accuracy of K-NN classifier on training set: {:.2f}'
     .format(knn.score(X_train, y_train)))
print('Accuracy of K-NN classifier on test set: {:.2f}'
     .format(knn.score(X_test, y_test)))

# Linear Discriminant Analysis

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)
print('Accuracy of LDA classifier on training set: {:.2f}'
     .format(lda.score(X_train, y_train)))
print('Accuracy of LDA classifier on test set: {:.2f}'
     .format(lda.score(X_test, y_test)))

# Gaussian Naive Bayes

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_train, y_train)
print('Accuracy of GNB classifier on training set: {:.2f}'
     .format(gnb.score(X_train, y_train)))
print('Accuracy of GNB classifier on test set: {:.2f}'
     .format(gnb.score(X_test, y_test)))

# Support Vector Machine

from sklearn.svm import SVC
svm = SVC()
svm.fit(X_train, y_train)
print('Accuracy of SVM classifier on training set: {:.2f}'
     .format(svm.score(X_train, y_train)))
print('Accuracy of SVM classifier on test set: {:.2f}'
     .format(svm.score(X_test, y_test)))

"""**Podemos perceber que o melhor modelo, baseado na acurácia, teve uma precisão de 100% nos treinos e de 99% nos testes. O modelo do algoritmo de árvore de decisão foi o que melhor se saiu na avaliação de acurácia.** 


---


**Entretanto, devemos realizar outros testes para ter total certeza se nosso modelo está totalmente correto.
Esses testes medem as seguintes métricas de classificação:**

1.   **Accurancy (já medido):** indica uma performace geral do modelo. Dentre todas as classificações, quantas o modelo classificou corretamente;
2.   **Recall:** dentre todas as situações de classe positivo com valor esperado, qunatas estão corretas;
1.   **Precision:** dentre todas as situações de classe positivo que o modelo fez, quantas estão certas;
2.  **F1-Score:** média harmônica entre precision e recall.








"""

dtree = DecisionTreeClassifier()
dtree.fit(X_train,y_train)

predictions = dtree.predict(X_test)
from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test,predictions))

print(confusion_matrix(y_test,predictions))

"""**Percebemos que o algorítmo de árvore de decisão apresenta uma ótima acurácia. 
A matrix de confusão nos mostrou que apenas um erro foi cometido no teste.**

**Também podemos notar, a partir do relatório de classificação, que os parâmetros classificatórios do algoritmo estão muito próximos de 100%**

**Contudo, os testes ainda são de pequenas proporções. Para melhor avaliação da eficiência desse modelo iremos montar uma visualização da árvore de decisão.**
"""

#visualização da árvore de decisão
from IPython.display import Image  
from sklearn.externals.six import StringIO  
from sklearn.tree import export_graphviz
import pydot 

features = list(stars.columns[1:5])
features

dot_data = StringIO()  
export_graphviz(dtree, out_file=dot_data,feature_names=features,filled=True,rounded=True)

graph = pydot.graph_from_dot_data(dot_data.getvalue())  
Image(graph[0].create_png())

"""**Agora iremos comparar nossa Árvore de decisão com o modelo de Random Forest.**"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=200)
rfc.fit(X_train, y_train)

rfc_pred = rfc.predict(X_test)

print(confusion_matrix(y_test,rfc_pred))

print(classification_report(y_test,rfc_pred))

"""##**Podemos perceber que ambas chegam em uma eficiência muito parecida, demonstrando uma acurácia, precisão, recall e F1 de 99%**

##**Consequentemente, tanto o modelo de árvore de decisão como o modelo de random forest podem ser utilizados para a classificação do tipo de estrela neste data set.**
"""